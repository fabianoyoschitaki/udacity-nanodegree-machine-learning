{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Using Supervised Classification Algorithms to Predict Bank Term Deposit Subscription\n",
    "Fabiano Shoji Yoschitaki  \n",
    "July 8th, 2018\n",
    "\n",
    "## Project Design\n",
    "\n",
    "As it is described the capstone proposal document, the project is composed of the following activites:\n",
    "\n",
    "- **Data and Library Loading: ** the first step is to load the Bank Marketing data set in the CSV format from the UCI's Machine Learning Repository and all the libraries needed for the project.\n",
    "\n",
    "- **Data Exploration: ** in this step, we'll do some tasks like: visualize the data, print some samples, check its dimensions, check the most relevant features, show its statistical summary.  \n",
    "\n",
    "- **Data Preparation: ** after exploring the data, pre-processing tasks will be done: data cleaning, remove null values, convert categorical features into dummy/indicator variables and split the data into training and testing datasets. \n",
    "\n",
    "- **Model Selection: ** with the prepared data, various supervised classification algorithms will be experimented in order to find compare their results and choose the best one (taking into account the accuracy score) for model tuning.  \n",
    "\n",
    "- **Model Tuning: ** after we choose the best model, grid search cross validation will be applied with the objective to tune the hyper-parameters of the model.\n",
    "\n",
    "- **Final Evaluation: ** in this step, the accuracy score of the tuned model will be evaluated by applying it to the testing dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 1. Data and Library Loading\n",
    "In this section, we will load the dataset and the libraries used in the project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Library Loading\n",
    "Loading all libraries needed for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Data Loading\n",
    "Loading the dataset from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank dataset was loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "bank_full_data = pd.read_csv('bank-full.csv', delimiter=';')\n",
    "print(\"Bank dataset was loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 2. Data Exploration\n",
    "Here we will apply some methods/techniques for Exploratory Data Analysis to better understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Data Dimensions\n",
    "Printing the first 10 rows from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 45211 rows and 17 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset has {} rows and {} columns\".format(bank_full_data.shape[0], bank_full_data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Data Information\n",
    "Printing information about column dtypes, non null values and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      "age          45211 non-null int64\n",
      "job          45211 non-null object\n",
      "marital      45211 non-null object\n",
      "education    45211 non-null object\n",
      "default      45211 non-null object\n",
      "balance      45211 non-null int64\n",
      "housing      45211 non-null object\n",
      "loan         45211 non-null object\n",
      "contact      45211 non-null object\n",
      "day          45211 non-null int64\n",
      "month        45211 non-null object\n",
      "duration     45211 non-null int64\n",
      "campaign     45211 non-null int64\n",
      "pdays        45211 non-null int64\n",
      "previous     45211 non-null int64\n",
      "poutcome     45211 non-null object\n",
      "y            45211 non-null object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "bank_full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Data Samples\n",
    "Printing the first 10 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>231</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>447</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>divorced</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>yes</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>121</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>593</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job   marital  education default  balance housing loan  \\\n",
       "0   58    management   married   tertiary      no     2143     yes   no   \n",
       "1   44    technician    single  secondary      no       29     yes   no   \n",
       "2   33  entrepreneur   married  secondary      no        2     yes  yes   \n",
       "3   47   blue-collar   married    unknown      no     1506     yes   no   \n",
       "4   33       unknown    single    unknown      no        1      no   no   \n",
       "5   35    management   married   tertiary      no      231     yes   no   \n",
       "6   28    management    single   tertiary      no      447     yes  yes   \n",
       "7   42  entrepreneur  divorced   tertiary     yes        2     yes   no   \n",
       "8   58       retired   married    primary      no      121     yes   no   \n",
       "9   43    technician    single  secondary      no      593     yes   no   \n",
       "\n",
       "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
       "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
       "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
       "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
       "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
       "4  unknown    5   may       198         1     -1         0  unknown  no  \n",
       "5  unknown    5   may       139         1     -1         0  unknown  no  \n",
       "6  unknown    5   may       217         1     -1         0  unknown  no  \n",
       "7  unknown    5   may       380         1     -1         0  unknown  no  \n",
       "8  unknown    5   may        50         1     -1         0  unknown  no  \n",
       "9  unknown    5   may        55         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_full_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Data Descriptive Statistics\n",
    "Visualizing statistical summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "      <td>45211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.936210</td>\n",
       "      <td>1362.272058</td>\n",
       "      <td>15.806419</td>\n",
       "      <td>258.163080</td>\n",
       "      <td>2.763841</td>\n",
       "      <td>40.197828</td>\n",
       "      <td>0.580323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.618762</td>\n",
       "      <td>3044.765829</td>\n",
       "      <td>8.322476</td>\n",
       "      <td>257.527812</td>\n",
       "      <td>3.098021</td>\n",
       "      <td>100.128746</td>\n",
       "      <td>2.303441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>448.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>1428.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>102127.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>4918.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>275.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        balance           day      duration      campaign  \\\n",
       "count  45211.000000   45211.000000  45211.000000  45211.000000  45211.000000   \n",
       "mean      40.936210    1362.272058     15.806419    258.163080      2.763841   \n",
       "std       10.618762    3044.765829      8.322476    257.527812      3.098021   \n",
       "min       18.000000   -8019.000000      1.000000      0.000000      1.000000   \n",
       "25%       33.000000      72.000000      8.000000    103.000000      1.000000   \n",
       "50%       39.000000     448.000000     16.000000    180.000000      2.000000   \n",
       "75%       48.000000    1428.000000     21.000000    319.000000      3.000000   \n",
       "max       95.000000  102127.000000     31.000000   4918.000000     63.000000   \n",
       "\n",
       "              pdays      previous  \n",
       "count  45211.000000  45211.000000  \n",
       "mean      40.197828      0.580323  \n",
       "std      100.128746      2.303441  \n",
       "min       -1.000000      0.000000  \n",
       "25%       -1.000000      0.000000  \n",
       "50%       -1.000000      0.000000  \n",
       "75%       -1.000000      0.000000  \n",
       "max      871.000000    275.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_full_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Data General Information\n",
    "Exploring features information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of clients: 45211\n",
      "Number of clients who have subscribed: 5289\n",
      "Number of clients who haven't subscribed: 39922\n",
      "Subscription rate of the dataset: 11.70%\n",
      "No-Subscription rate of the dataset: 88.30%\n"
     ]
    }
   ],
   "source": [
    "# Calculate number of clients\n",
    "n_clients = len(bank_full_data)\n",
    "\n",
    "# Calculate clients who have subscribed\n",
    "n_clients_subscribed = len(bank_full_data[bank_full_data['y'] == 'yes'])\n",
    "\n",
    "# Calculate clients who haven't subscribed\n",
    "n_clients_not_subscribed = len(bank_full_data[bank_full_data['y'] == 'no'])\n",
    "\n",
    "# Calculate graduation rate\n",
    "subscription_rate = float(n_clients_subscribed)/float(n_clients) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of clients: {}\".format(n_clients))\n",
    "print(\"Number of clients who have subscribed: {}\".format(n_clients_subscribed))\n",
    "print(\"Number of clients who haven't subscribed: {}\".format(n_clients_not_subscribed))\n",
    "print(\"Subscription rate of the dataset: {:.2f}%\".format(subscription_rate))\n",
    "print(\"No-Subscription rate of the dataset: {:.2f}%\".format(100-subscription_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Visualization\n",
    "Generating some graphs for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc14be10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(\"Distribution of Clients Subscribed vs Not Subscribed\")\n",
    "bank_full_data.groupby(\"y\")['y'].count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_histogram = sns.distplot(bank_full_data['age'], bins=10)\n",
    "plt.title('Distribution by Age')\n",
    "age_histogram.figure.set_size_inches(12, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(12, 6))\n",
    "mask = np.zeros_like(bank_full_data.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(bank_full_data.corr(), mask=mask, annot=True, cmap=\"Blues\")\n",
    "figure.suptitle('Correlation Matrix', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 3. Data Preparation\n",
    "In this section we will apply some methods/techniques for Data Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Checking for null values\n",
    "If the dataset has null values, we must "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Preprocessing Features\n",
    "Applying pandas_get_dummies to convert categorical features into binary variables. Also, we'll replace 'yes' -> 1, 'no' -> 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index=X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  \n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (49 total features): \n",
      "['age', 'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary', 'education_secondary', 'education_tertiary', 'education_unknown', 'default', 'balance', 'housing', 'loan', 'contact_cellular', 'contact_telephone', 'contact_unknown', 'day', 'month_apr', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'duration', 'campaign', 'pdays', 'previous', 'poutcome_failure', 'poutcome_other', 'poutcome_success', 'poutcome_unknown', 'y']\n"
     ]
    }
   ],
   "source": [
    "bank_full_data = preprocess_features(bank_full_data)\n",
    "print(\"Processed feature columns ({} total features): \\n{}\".format(len(bank_full_data.columns), list(bank_full_data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Identifying Feature and Target Columns\n",
    "Separating the feature columns from the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['age', 'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary', 'education_secondary', 'education_tertiary', 'education_unknown', 'default', 'balance', 'housing', 'loan', 'contact_cellular', 'contact_telephone', 'contact_unknown', 'day', 'month_apr', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'duration', 'campaign', 'pdays', 'previous', 'poutcome_failure', 'poutcome_other', 'poutcome_success', 'poutcome_unknown']\n",
      "\n",
      "Target column: y\n",
      "\n",
      "Feature values:\n",
      "   age  job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
      "0   58           0                0                 0              0   \n",
      "1   44           0                0                 0              0   \n",
      "2   33           0                0                 1              0   \n",
      "3   47           0                1                 0              0   \n",
      "4   33           0                0                 0              0   \n",
      "\n",
      "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
      "0               1            0                  0             0            0   \n",
      "1               0            0                  0             0            0   \n",
      "2               0            0                  0             0            0   \n",
      "3               0            0                  0             0            0   \n",
      "4               0            0                  0             0            0   \n",
      "\n",
      "         ...         month_oct  month_sep  duration  campaign  pdays  \\\n",
      "0        ...                 0          0       261         1     -1   \n",
      "1        ...                 0          0       151         1     -1   \n",
      "2        ...                 0          0        76         1     -1   \n",
      "3        ...                 0          0        92         1     -1   \n",
      "4        ...                 0          0       198         1     -1   \n",
      "\n",
      "   previous  poutcome_failure  poutcome_other  poutcome_success  \\\n",
      "0         0                 0               0                 0   \n",
      "1         0                 0               0                 0   \n",
      "2         0                 0               0                 0   \n",
      "3         0                 0               0                 0   \n",
      "4         0                 0               0                 0   \n",
      "\n",
      "   poutcome_unknown  \n",
      "0                 1  \n",
      "1                 1  \n",
      "2                 1  \n",
      "3                 1  \n",
      "4                 1  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(bank_full_data.columns[:-1])\n",
    "\n",
    "# Extract target column 'y' (subscribed/not subscribed)\n",
    "target_col = bank_full_data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = bank_full_data[feature_cols]\n",
    "y_all = bank_full_data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>...</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
       "0   58           0                0                 0              0   \n",
       "1   44           0                0                 0              0   \n",
       "2   33           0                0                 1              0   \n",
       "3   47           0                1                 0              0   \n",
       "4   33           0                0                 0              0   \n",
       "5   35           0                0                 0              0   \n",
       "6   28           0                0                 0              0   \n",
       "7   42           0                0                 1              0   \n",
       "8   58           0                0                 0              0   \n",
       "9   43           0                0                 0              0   \n",
       "\n",
       "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
       "0               1            0                  0             0            0   \n",
       "1               0            0                  0             0            0   \n",
       "2               0            0                  0             0            0   \n",
       "3               0            0                  0             0            0   \n",
       "4               0            0                  0             0            0   \n",
       "5               1            0                  0             0            0   \n",
       "6               1            0                  0             0            0   \n",
       "7               0            0                  0             0            0   \n",
       "8               0            1                  0             0            0   \n",
       "9               0            0                  0             0            0   \n",
       "\n",
       "         ...         month_oct  month_sep  duration  campaign  pdays  \\\n",
       "0        ...                 0          0       261         1     -1   \n",
       "1        ...                 0          0       151         1     -1   \n",
       "2        ...                 0          0        76         1     -1   \n",
       "3        ...                 0          0        92         1     -1   \n",
       "4        ...                 0          0       198         1     -1   \n",
       "5        ...                 0          0       139         1     -1   \n",
       "6        ...                 0          0       217         1     -1   \n",
       "7        ...                 0          0       380         1     -1   \n",
       "8        ...                 0          0        50         1     -1   \n",
       "9        ...                 0          0        55         1     -1   \n",
       "\n",
       "   previous  poutcome_failure  poutcome_other  poutcome_success  \\\n",
       "0         0                 0               0                 0   \n",
       "1         0                 0               0                 0   \n",
       "2         0                 0               0                 0   \n",
       "3         0                 0               0                 0   \n",
       "4         0                 0               0                 0   \n",
       "5         0                 0               0                 0   \n",
       "6         0                 0               0                 0   \n",
       "7         0                 0               0                 0   \n",
       "8         0                 0               0                 0   \n",
       "9         0                 0               0                 0   \n",
       "\n",
       "   poutcome_unknown  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "5                 1  \n",
       "6                 1  \n",
       "7                 1  \n",
       "8                 1  \n",
       "9                 1  \n",
       "\n",
       "[10 rows x 48 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Training and Testing Datasets\n",
    "Splitting data into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 31647 samples with 11.79% of 'yes' (subscribed) and 88.21% of 'no' (not subscribed).\n",
      "Testing set has 13564 samples with 11.49% of 'yes' (subscribed) and 88.51% of 'no' (not subscribed).\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split the dataset into the number of training and testing points above.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.3, random_state=10)\n",
    "\n",
    "print(\"Training set has {} samples with {:.2f}% of 'yes' (subscribed) and {:.2f}% of 'no' (not subscribed).\"\n",
    "      .format(X_train.shape[0], \n",
    "        100 * len(y_train[y_train == 1])/len(y_train), \n",
    "        100 * len(y_train[y_train == 0])/len(y_train)))\n",
    "\n",
    "print(\"Testing set has {} samples with {:.2f}% of 'yes' (subscribed) and {:.2f}% of 'no' (not subscribed).\"\n",
    "      .format(X_test.shape[0], \n",
    "        100 * len(y_test[y_test == 1])/len(y_test), \n",
    "        100 * len(y_test[y_test == 0])/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Feature Scaling\n",
    "Rescaling the features for them to have standard normal distribution with mean 0 and a standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# Keep column header names for final importance plot.\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train), columns=X_all.columns)\n",
    "X_test = pd.DataFrame(sc.transform(X_test), columns=X_all.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 4. Model Selection\n",
    "In this section we will select some supervised classification algorithms in order to choose the best one to tune in the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Selected Supervised Classification Algorithms\n",
    "List of chosen algorithms:\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees\n",
    "- Bagging (Ensemble Methods) \n",
    "- AdaBoost (Ensemble Methods) \n",
    "- Random Forest (Ensemble Methods)\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression (LR)\n",
    "- eXtreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "classifiers.append(GaussianNB())\n",
    "classifiers.append(DecisionTreeClassifier(random_state=1))\n",
    "classifiers.append(BaggingClassifier(random_state=1))\n",
    "classifiers.append(AdaBoostClassifier(random_state=1))\n",
    "classifiers.append(RandomForestClassifier(random_state=1))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(SGDClassifier())\n",
    "classifiers.append(SVC(random_state=1))\n",
    "classifiers.append(LogisticRegression(random_state=1))\n",
    "classifiers.append(XGBClassifier(random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Training, Predicting and Scoring Functions\n",
    "Defining functions to train models, predict labels and show metric results: accuracy and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end-start))\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on accuracy score. '''    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()    \n",
    "    return y_pred\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifier based on accuracy and F1-score. '''\n",
    "    print(\"\\nTraining classifier {} using a training set size of {}\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Predict labels for training and testing sets\n",
    "    y_pred_train = predict_labels(clf, X_train, y_train)\n",
    "    y_pred_test = predict_labels(clf, X_test, y_test)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"Accuracy score for training set: {:.4f}.\".format(accuracy_score(y_train, y_pred_train)))\n",
    "    print(\"F1 score for training set: {:.4f}.\".format(f1_score(y_train, y_pred_train)))\n",
    "    print(\"Accuracy score for test set: {:.4f}.\".format(accuracy_score(y_test, y_pred_test)))\n",
    "    print(\"F1 score for test set: {:.4f}.\".format(f1_score(y_test, y_pred_test)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Evaluation\n",
    "Evaluating all classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:    \n",
    "    train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 5. Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Cross Validation\n",
    "Creating random data splits for training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_sets = ShuffleSplit(test_size=0.20, random_state=1)\n",
    "cv_sets.get_n_splits(X_train)\n",
    "print(cv_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Scoring for Grid Search Cross Validation\n",
    "Creating multiple metric evaluation: Accuracy and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'Accuracy': 'accuracy', \n",
    "    'F1-Score': 'f1'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Default XGBoost\n",
    "Creating XGBoost instance for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 4.9085 seconds\n",
      "Accuracy score for training set: 0.9085.\n",
      "F1 score for training set: 0.5046.\n",
      "Accuracy score for test set: 0.9082.\n",
      "F1 score for test set: 0.4916.\n"
     ]
    }
   ],
   "source": [
    "model_v0 = XGBClassifier(\n",
    "    random_state=1)\n",
    "train_predict(model_v0, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. First tune: scale_post_weight\n",
    "Tuning scale_pos_weight parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': 'accuracy', 'F1-Score': 'f1'}, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_0 = {\n",
    "    'scale_pos_weight': [x for x in range(1,11)]\n",
    "}\n",
    "gs_0 = GridSearchCV(\n",
    "    estimator=model_v0, \n",
    "    param_grid=params_0,\n",
    "    scoring=scoring, \n",
    "    cv=10, \n",
    "    refit='Accuracy')\n",
    "gs_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'scale_pos_weight': 1}, best score: 0.904098334755269\n"
     ]
    }
   ],
   "source": [
    "tuned_params['scale_pos_weight'] = gs_0.best_params_['scale_pos_weight']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(tuned_params, gs_0.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 4.8145 seconds\n",
      "Accuracy score for training set: 0.9085.\n",
      "F1 score for training set: 0.5046.\n",
      "Accuracy score for test set: 0.9082.\n",
      "F1 score for test set: 0.4916.\n"
     ]
    }
   ],
   "source": [
    "model_v1 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'])\n",
    "train_predict(model_v1, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5. Second tune: objective\n",
    "Tuning objective parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'objective': ['reg:linear', 'reg:logistic', 'binary:logistic', 'binary:logitraw', 'binary:hinge', 'count:poisson']},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': 'accuracy', 'F1-Score': 'f1'}, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_1 = {\n",
    "    'objective': [\n",
    "        'reg:linear', \n",
    "        'reg:logistic',\n",
    "        'binary:logistic',\n",
    "        'binary:logitraw',\n",
    "        'binary:hinge',\n",
    "        'count:poisson',]\n",
    "}\n",
    " \n",
    "gs_1 = GridSearchCV(\n",
    "    estimator=model_v1, \n",
    "    param_grid=params_1, \n",
    "    scoring=scoring, \n",
    "    cv=10, \n",
    "    refit='Accuracy')\n",
    "gs_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'objective': 'reg:logistic'}, best score: 0.904098334755269\n"
     ]
    }
   ],
   "source": [
    "tuned_params['objective'] = gs_1.best_params_['objective']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_1.best_params_, gs_1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 4.7975 seconds\n",
      "Accuracy score for training set: 0.9085.\n",
      "F1 score for training set: 0.5046.\n",
      "Accuracy score for test set: 0.9082.\n",
      "F1 score for test set: 0.4916.\n"
     ]
    }
   ],
   "source": [
    "model_v2 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'])\n",
    "train_predict(model_v2, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6. Third tune: max_depth and min_child_weight\n",
    "Tuning max_depth and min_child_weight parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:logistic', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3, 4, 5, 6, 7, 8], 'min_child_weight': [1, 2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': 'accuracy', 'F1-Score': 'f1'}, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2 = {\n",
    "    'max_depth': [x for x in range(3, 9)],\n",
    "    'min_child_weight': [x for x in range(1, 7)]\n",
    "}\n",
    "gs_2 = GridSearchCV(\n",
    "    estimator=model_v2, \n",
    "    param_grid=params_2,\n",
    "    scoring=scoring, \n",
    "    cv=10, \n",
    "    refit='Accuracy')\n",
    "gs_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'max_depth': 6, 'min_child_weight': 1}, best score: 0.9064682276361109\n"
     ]
    }
   ],
   "source": [
    "tuned_params['max_depth'] = gs_2.best_params_['max_depth']\n",
    "tuned_params['min_child_weight'] = gs_2.best_params_['min_child_weight']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_2.best_params_, gs_2.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 15.3295 seconds\n",
      "Accuracy score for training set: 0.9321.\n",
      "F1 score for training set: 0.6650.\n",
      "Accuracy score for test set: 0.9109.\n",
      "F1 score for test set: 0.5476.\n"
     ]
    }
   ],
   "source": [
    "model_v3 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'])\n",
    "train_predict(model_v3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7. Fourth tune: subsample and colsample_bytree\n",
    "Tuning subsample and colsample_bytree parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:logistic', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': 'accuracy', 'F1-Score': 'f1'}, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_3 = {\n",
    "    'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "gs_3 = GridSearchCV(\n",
    "    estimator=model_v3, \n",
    "    param_grid=params_3,\n",
    "    scoring=scoring, \n",
    "    cv=10, \n",
    "    refit='Accuracy')\n",
    "gs_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'colsample_bytree': 0.6, 'subsample': 1.0}, best score: 0.9069422062122792\n"
     ]
    }
   ],
   "source": [
    "tuned_params['colsample_bytree'] = gs_3.best_params_['colsample_bytree']\n",
    "tuned_params['subsample'] = gs_3.best_params_['subsample']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_3.best_params_, gs_3.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 8.7920 seconds\n",
      "Accuracy score for training set: 0.9311.\n",
      "F1 score for training set: 0.6556.\n",
      "Accuracy score for test set: 0.9130.\n",
      "F1 score for test set: 0.5520.\n"
     ]
    }
   ],
   "source": [
    "model_v4 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'], \n",
    "    subsample=tuned_params['subsample'], \n",
    "    colsample_bytree=tuned_params['colsample_bytree'])\n",
    "train_predict(model_v4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.8. Fifth tune: reg_alpha and reg_lambda\n",
    "Tuning reg_alpha and reg_lambda parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:logistic', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1.0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'reg_alpha': [0, 1, 2, 3, 4, 5], 'reg_lambda': [1, 2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': 'accuracy', 'F1-Score': 'f1'}, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_4 = {\n",
    "    'reg_alpha':[x for x in range(0, 6)],\n",
    "    'reg_lambda':[x for x in range(1, 7)]\n",
    "}\n",
    "gs_4 = GridSearchCV(\n",
    "    estimator=model_v4, \n",
    "    param_grid=params_4, \n",
    "    scoring=scoring, \n",
    "    cv=10,\n",
    "    refit='Accuracy')\n",
    "gs_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'reg_alpha': 1, 'reg_lambda': 5}, best score: 0.9073529876449584\n"
     ]
    }
   ],
   "source": [
    "tuned_params['reg_alpha'] = gs_4.best_params_['reg_alpha']\n",
    "tuned_params['reg_lambda'] = gs_4.best_params_['reg_lambda']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_4.best_params_, gs_4.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 8.0698 seconds\n",
      "Accuracy score for training set: 0.9244.\n",
      "F1 score for training set: 0.6205.\n",
      "Accuracy score for test set: 0.9109.\n",
      "F1 score for test set: 0.5375.\n"
     ]
    }
   ],
   "source": [
    "model_v5 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'], \n",
    "    subsample=tuned_params['subsample'], \n",
    "    colsample_bytree=tuned_params['colsample_bytree'],\n",
    "    reg_alpha=tuned_params['reg_alpha'],\n",
    "    reg_lambda=tuned_params['reg_lambda'])\n",
    "train_predict(model_v5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.9. Sixth tune: gamma\n",
    "Tuning gamma parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.6, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:logistic', random_state=1,\n",
       "       reg_alpha=1, reg_lambda=5, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1.0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.30000000000000004, 0.4, 0.5, 0.6000000000000001, 0.7000000000000001, 0.8, 0.9, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': 'accuracy', 'F1-Score': 'f1'}, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_5 = {\n",
    "    'gamma':[x * 0.1 for x in range(0, 11)]\n",
    "}\n",
    "gs_5 = GridSearchCV(\n",
    "    estimator=model_v5, \n",
    "    param_grid=params_5,\n",
    "    scoring=scoring, \n",
    "    cv=10, \n",
    "    refit='Accuracy')\n",
    "gs_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'gamma': 0.0}, best score: 0.9073529876449584\n"
     ]
    }
   ],
   "source": [
    "tuned_params['gamma'] = gs_5.best_params_['gamma']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_5.best_params_, gs_5.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 7.5205 seconds\n",
      "Accuracy score for training set: 0.9244.\n",
      "F1 score for training set: 0.6205.\n",
      "Accuracy score for test set: 0.9109.\n",
      "F1 score for test set: 0.5375.\n"
     ]
    }
   ],
   "source": [
    "model_v6 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'], \n",
    "    subsample=tuned_params['subsample'], \n",
    "    colsample_bytree=tuned_params['colsample_bytree'],\n",
    "    reg_alpha=tuned_params['reg_alpha'],\n",
    "    reg_lambda=tuned_params['reg_lambda'],\n",
    "    gamma=tuned_params['gamma'])\n",
    "train_predict(model_v6, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.10. Tuned Parameters\n",
    "Printing the best values found for model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter                 Value     \n",
      "scale_pos_weight          1         \n",
      "objective                 reg:logistic\n",
      "max_depth                 6         \n",
      "min_child_weight          1         \n",
      "colsample_bytree          0.6       \n",
      "subsample                 1.0       \n",
      "reg_alpha                 1         \n",
      "reg_lambda                5         \n",
      "gamma                     0.0       \n"
     ]
    }
   ],
   "source": [
    "print(\"{:<25} {:<10}\".format('Parameter','Value'))\n",
    "for k, v in tuned_params.items():\n",
    "    print(\"{:<25} {:<10}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 6. Final Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Model Benchmark\n",
    "Creating a Dummy Classifier which Predicts the Majority Class and XGBoost untuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier DummyClassifier using a training set size of 31647\n",
      "Trained model in 0.0740 seconds\n",
      "Accuracy score for training set: 0.8821.\n",
      "F1 score for training set: 0.0000.\n",
      "Accuracy score for test set: 0.8851.\n",
      "F1 score for test set: 0.0000.\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=1)\n",
    "train_predict(dummy_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 6.2647 seconds\n",
      "Accuracy score for training set: 0.9085.\n",
      "F1 score for training set: 0.5046.\n",
      "Accuracy score for test set: 0.9082.\n",
      "F1 score for test set: 0.4916.\n"
     ]
    }
   ],
   "source": [
    "xgb_untuned_model = XGBClassifier(random_state=1)\n",
    "train_predict(xgb_untuned_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 7.6725 seconds\n",
      "Accuracy score for training set: 0.9238.\n",
      "F1 score for training set: 0.6186.\n",
      "Accuracy score for test set: 0.9112.\n",
      "F1 score for test set: 0.5408.\n"
     ]
    }
   ],
   "source": [
    "final_xgb_tuned_model = XGBClassifier(\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'], \n",
    "    subsample=tuned_params['subsample'], \n",
    "    colsample_bytree=tuned_params['colsample_bytree'],\n",
    "    reg_alpha=tuned_params['reg_alpha'],\n",
    "    reg_lambda=tuned_params['reg_lambda'],\n",
    "    gamma=tuned_params['gamma'])\n",
    "train_predict(final_xgb_tuned_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Feature Importance\n",
    "Printing feature importance of the final tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = plot_importance(final_xgb_tuned_model, max_num_features=6)\n",
    "chart.figure.set_size_inches(14, 5)\n",
    "plt.title('Top 5 Importance Features',fontsize=15)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Feature',fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
