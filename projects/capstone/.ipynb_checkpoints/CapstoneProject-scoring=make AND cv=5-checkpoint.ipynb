{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "## Using Supervised Classification Algorithms to Predict Bank Term Deposit Subscription\n",
    "Fabiano Shoji Yoschitaki  \n",
    "July 8th, 2018\n",
    "\n",
    "## Project Design\n",
    "\n",
    "As it is described the capstone proposal document, the project is composed of the following activites:\n",
    "\n",
    "- **Data and Library Loading: ** the first step is to load the Bank Marketing data set in the CSV format from the UCI's Machine Learning Repository and all the libraries needed for the project.\n",
    "\n",
    "- **Data Exploration: ** in this step, we'll do some tasks like: visualize the data, print some samples, check its dimensions, check the most relevant features, show its statistical summary.  \n",
    "\n",
    "- **Data Preparation: ** after exploring the data, pre-processing tasks will be done: data cleaning, remove null values, convert categorical features into dummy/indicator variables and split the data into training and testing datasets. \n",
    "\n",
    "- **Model Selection: ** with the prepared data, various supervised classification algorithms will be experimented in order to find compare their results and choose the best one (taking into account the accuracy score) for model tuning.  \n",
    "\n",
    "- **Model Tuning: ** after we choose the best model, grid search cross validation will be applied with the objective to tune the hyper-parameters of the model.\n",
    "\n",
    "- **Final Evaluation: ** in this step, the accuracy score of the tuned model will be evaluated by applying it to the testing dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 1. Data and Library Loading\n",
    "In this section, we will load the dataset and the libraries used in the project.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Library Loading\n",
    "Loading all libraries needed for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from time import time\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Data Loading\n",
    "Loading the dataset from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank dataset was loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "bank_full_data = pd.read_csv('bank-full.csv', delimiter=';')\n",
    "print(\"Bank dataset was loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 2. Data Exploration\n",
    "Here we will apply some methods/techniques for Exploratory Data Analysis to better understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Data Dimensions\n",
    "Printing the first 10 rows from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dataset has {} rows and {} columns\".format(bank_full_data.shape[0], bank_full_data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Data Information\n",
    "Printing information about column dtypes, non null values and memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Data Samples\n",
    "Printing the first 10 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Data Descriptive Statistics\n",
    "Visualizing statistical summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Data General Information\n",
    "Exploring features information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of clients\n",
    "n_clients = len(bank_full_data)\n",
    "\n",
    "# Calculate clients who have subscribed\n",
    "n_clients_subscribed = len(bank_full_data[bank_full_data['y'] == 'yes'])\n",
    "\n",
    "# Calculate clients who haven't subscribed\n",
    "n_clients_not_subscribed = len(bank_full_data[bank_full_data['y'] == 'no'])\n",
    "\n",
    "# Calculate graduation rate\n",
    "subscription_rate = float(n_clients_subscribed)/float(n_clients) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of clients: {}\".format(n_clients))\n",
    "print(\"Number of clients who have subscribed: {}\".format(n_clients_subscribed))\n",
    "print(\"Number of clients who haven't subscribed: {}\".format(n_clients_not_subscribed))\n",
    "print(\"Subscription rate of the dataset: {:.2f}%\".format(subscription_rate))\n",
    "print(\"No-Subscription rate of the dataset: {:.2f}%\".format(100-subscription_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6. Visualization\n",
    "Generating some graphs for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.title(\"Distribution of Clients Subscribed vs Not Subscribed\")\n",
    "bank_full_data.groupby(\"y\")['y'].count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_histogram = sns.distplot(bank_full_data['age'], bins=10)\n",
    "plt.title('Distribution by Age')\n",
    "age_histogram.figure.set_size_inches(12, 6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(12, 6))\n",
    "mask = np.zeros_like(bank_full_data.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(bank_full_data.corr(), mask=mask, annot=True, cmap=\"Blues\")\n",
    "figure.suptitle('Correlation Matrix', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 3. Data Preparation\n",
    "In this section we will apply some methods/techniques for Data Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Checking for null values\n",
    "If the dataset has null values, we must "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_full_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Preprocessing Features\n",
    "Applying pandas_get_dummies to convert categorical features into binary variables. Also, we'll replace 'yes' -> 1, 'no' -> 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index=X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  \n",
    "                    \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (49 total features): \n",
      "['age', 'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary', 'education_secondary', 'education_tertiary', 'education_unknown', 'default', 'balance', 'housing', 'loan', 'contact_cellular', 'contact_telephone', 'contact_unknown', 'day', 'month_apr', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'duration', 'campaign', 'pdays', 'previous', 'poutcome_failure', 'poutcome_other', 'poutcome_success', 'poutcome_unknown', 'y']\n"
     ]
    }
   ],
   "source": [
    "bank_full_data = preprocess_features(bank_full_data)\n",
    "print(\"Processed feature columns ({} total features): \\n{}\".format(len(bank_full_data.columns), list(bank_full_data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Identifying Feature and Target Columns\n",
    "Separating the feature columns from the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns:\n",
      "['age', 'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid', 'job_management', 'job_retired', 'job_self-employed', 'job_services', 'job_student', 'job_technician', 'job_unemployed', 'job_unknown', 'marital_divorced', 'marital_married', 'marital_single', 'education_primary', 'education_secondary', 'education_tertiary', 'education_unknown', 'default', 'balance', 'housing', 'loan', 'contact_cellular', 'contact_telephone', 'contact_unknown', 'day', 'month_apr', 'month_aug', 'month_dec', 'month_feb', 'month_jan', 'month_jul', 'month_jun', 'month_mar', 'month_may', 'month_nov', 'month_oct', 'month_sep', 'duration', 'campaign', 'pdays', 'previous', 'poutcome_failure', 'poutcome_other', 'poutcome_success', 'poutcome_unknown']\n",
      "\n",
      "Target column: y\n",
      "\n",
      "Feature values:\n",
      "   age  job_admin.  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
      "0   58           0                0                 0              0   \n",
      "1   44           0                0                 0              0   \n",
      "2   33           0                0                 1              0   \n",
      "3   47           0                1                 0              0   \n",
      "4   33           0                0                 0              0   \n",
      "\n",
      "   job_management  job_retired  job_self-employed  job_services  job_student  \\\n",
      "0               1            0                  0             0            0   \n",
      "1               0            0                  0             0            0   \n",
      "2               0            0                  0             0            0   \n",
      "3               0            0                  0             0            0   \n",
      "4               0            0                  0             0            0   \n",
      "\n",
      "         ...         month_oct  month_sep  duration  campaign  pdays  \\\n",
      "0        ...                 0          0       261         1     -1   \n",
      "1        ...                 0          0       151         1     -1   \n",
      "2        ...                 0          0        76         1     -1   \n",
      "3        ...                 0          0        92         1     -1   \n",
      "4        ...                 0          0       198         1     -1   \n",
      "\n",
      "   previous  poutcome_failure  poutcome_other  poutcome_success  \\\n",
      "0         0                 0               0                 0   \n",
      "1         0                 0               0                 0   \n",
      "2         0                 0               0                 0   \n",
      "3         0                 0               0                 0   \n",
      "4         0                 0               0                 0   \n",
      "\n",
      "   poutcome_unknown  \n",
      "0                 1  \n",
      "1                 1  \n",
      "2                 1  \n",
      "3                 1  \n",
      "4                 1  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(bank_full_data.columns[:-1])\n",
    "\n",
    "# Extract target column 'y' (subscribed/not subscribed)\n",
    "target_col = bank_full_data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = bank_full_data[feature_cols]\n",
    "y_all = bank_full_data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Training and Testing Datasets\n",
    "Splitting data into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 31647 samples with 11.79% of 'yes' (subscribed) and 88.21% of 'no' (not subscribed).\n",
      "Testing set has 13564 samples with 11.49% of 'yes' (subscribed) and 88.51% of 'no' (not subscribed).\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split the dataset into the number of training and testing points above.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.3, random_state=10)\n",
    "\n",
    "print(\"Training set has {} samples with {:.2f}% of 'yes' (subscribed) and {:.2f}% of 'no' (not subscribed).\"\n",
    "      .format(X_train.shape[0], \n",
    "        100 * len(y_train[y_train == 1])/len(y_train), \n",
    "        100 * len(y_train[y_train == 0])/len(y_train)))\n",
    "\n",
    "print(\"Testing set has {} samples with {:.2f}% of 'yes' (subscribed) and {:.2f}% of 'no' (not subscribed).\"\n",
    "      .format(X_test.shape[0], \n",
    "        100 * len(y_test[y_test == 1])/len(y_test), \n",
    "        100 * len(y_test[y_test == 0])/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Feature Scaling\n",
    "Rescaling the features for them to have standard normal distribution with mean 0 and a standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# Keep column header names for final importance plot.\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train), columns=X_all.columns)\n",
    "X_test = pd.DataFrame(sc.transform(X_test), columns=X_all.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 4. Model Selection\n",
    "In this section we will select some supervised classification algorithms in order to choose the best one to tune in the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Selected Supervised Classification Algorithms\n",
    "List of chosen algorithms:\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees\n",
    "- Bagging (Ensemble Methods) \n",
    "- AdaBoost (Ensemble Methods) \n",
    "- Random Forest (Ensemble Methods)\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression (LR)\n",
    "- eXtreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "classifiers.append(GaussianNB())\n",
    "classifiers.append(DecisionTreeClassifier(random_state=1))\n",
    "classifiers.append(BaggingClassifier(random_state=1))\n",
    "classifiers.append(AdaBoostClassifier(random_state=1))\n",
    "classifiers.append(RandomForestClassifier(random_state=1))\n",
    "classifiers.append(LinearDiscriminantAnalysis())\n",
    "classifiers.append(KNeighborsClassifier())\n",
    "classifiers.append(SGDClassifier())\n",
    "classifiers.append(SVC(random_state=1))\n",
    "classifiers.append(LogisticRegression(random_state=1))\n",
    "classifiers.append(XGBClassifier(random_state=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Training, Predicting and Scoring Functions\n",
    "Defining functions to train models, predict labels and show metric results: accuracy and f1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Fits a classifier to the training data. '''\n",
    "    # Start the clock, train the classifier, then stop the clock\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()    \n",
    "    # Print the results\n",
    "    print(\"Trained model in {:.4f} seconds\".format(end-start))\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Makes predictions using a fit classifier based on accuracy score. '''    \n",
    "    # Start the clock, make predictions, then stop the clock\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()    \n",
    "    return y_pred\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Train and predict using a classifier based on accuracy and F1-score. '''\n",
    "    print(\"\\nTraining classifier {} using a training set size of {}\".format(clf.__class__.__name__, len(X_train)))\n",
    "    \n",
    "    # Train the classifier\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Predict labels for training and testing sets\n",
    "    y_pred_train = predict_labels(clf, X_train, y_train)\n",
    "    y_pred_test = predict_labels(clf, X_test, y_test)\n",
    "    \n",
    "    # Print the results of prediction for both training and testing\n",
    "    print(\"Accuracy score for training set: {:.4f}.\".format(accuracy_score(y_train, y_pred_train)))\n",
    "    print(\"F1 score for training set: {:.4f}.\".format(f1_score(y_train, y_pred_train)))\n",
    "    print(\"Accuracy score for test set: {:.4f}.\".format(accuracy_score(y_test, y_pred_test)))\n",
    "    print(\"F1 score for test set: {:.4f}.\".format(f1_score(y_test, y_pred_test)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Evaluation\n",
    "Evaluating all classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers:    \n",
    "    train_predict(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 5. Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1. Cross Validation\n",
    "Creating random data splits for training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(n_splits=10, random_state=1, test_size=0.2, train_size=None)\n"
     ]
    }
   ],
   "source": [
    "cv_sets = ShuffleSplit(test_size=0.20, random_state=1)\n",
    "cv_sets.get_n_splits(X_train)\n",
    "print(cv_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_params = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2. Scoring for Grid Search Cross Validation\n",
    "Creating multiple metric evaluation: Accuracy and F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    'Accuracy': make_scorer(accuracy_score), \n",
    "    'F1-Score': make_scorer(f1_score)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3. Default XGBoost\n",
    "Creating XGBoost instance for tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 5.6580 seconds\n",
      "Accuracy score for training set: 0.9085.\n",
      "F1 score for training set: 0.5046.\n",
      "Accuracy score for test set: 0.9082.\n",
      "F1 score for test set: 0.4916.\n"
     ]
    }
   ],
   "source": [
    "model_v0 = XGBClassifier(\n",
    "    random_state=1)\n",
    "train_predict(model_v0, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4. First tune: scale_post_weight\n",
    "Tuning scale_pos_weight parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'scale_pos_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': make_scorer(accuracy_score), 'F1-Score': make_scorer(f1_score)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_0 = {\n",
    "    'scale_pos_weight': [x for x in range(1,11)]\n",
    "}\n",
    "gs_0 = GridSearchCV(\n",
    "    estimator=model_v0, \n",
    "    param_grid=params_0,\n",
    "    scoring=scoring, \n",
    "    cv=5, \n",
    "    refit='Accuracy')\n",
    "gs_0.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'scale_pos_weight': 1}, best score: 0.9037191518943344\n"
     ]
    }
   ],
   "source": [
    "tuned_params['scale_pos_weight'] = gs_0.best_params_['scale_pos_weight']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(tuned_params, gs_0.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 7.2180 seconds\n",
      "Accuracy score for training set: 0.9085.\n",
      "F1 score for training set: 0.5046.\n",
      "Accuracy score for test set: 0.9082.\n",
      "F1 score for test set: 0.4916.\n"
     ]
    }
   ],
   "source": [
    "model_v1 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'])\n",
    "train_predict(model_v1, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5. Second tune: objective\n",
    "Tuning objective parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'objective': ['reg:linear', 'reg:logistic', 'binary:logistic', 'binary:logitraw', 'binary:hinge', 'count:poisson']},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': make_scorer(accuracy_score), 'F1-Score': make_scorer(f1_score)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_1 = {\n",
    "    'objective': [\n",
    "        'reg:linear', \n",
    "        'reg:logistic',\n",
    "        'binary:logistic',\n",
    "        'binary:logitraw',\n",
    "        'binary:hinge',\n",
    "        'count:poisson',]\n",
    "}\n",
    " \n",
    "gs_1 = GridSearchCV(\n",
    "    estimator=model_v1, \n",
    "    param_grid=params_1, \n",
    "    scoring=scoring, \n",
    "    cv=5, \n",
    "    refit='Accuracy')\n",
    "gs_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'objective': 'reg:linear'}, best score: 0.9039719404682909\n"
     ]
    }
   ],
   "source": [
    "tuned_params['objective'] = gs_1.best_params_['objective']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_1.best_params_, gs_1.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 7.0007 seconds\n",
      "Accuracy score for training set: 0.9086.\n",
      "F1 score for training set: 0.5088.\n",
      "Accuracy score for test set: 0.9082.\n",
      "F1 score for test set: 0.4978.\n"
     ]
    }
   ],
   "source": [
    "model_v2 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'])\n",
    "train_predict(model_v2, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6. Third tune: max_depth and min_child_weight\n",
    "Tuning max_depth and min_child_weight parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3, 4, 5, 6, 7, 8], 'min_child_weight': [1, 2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': make_scorer(accuracy_score), 'F1-Score': make_scorer(f1_score)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_2 = {\n",
    "    'max_depth': [x for x in range(3, 9)],\n",
    "    'min_child_weight': [x for x in range(1, 7)]\n",
    "}\n",
    "gs_2 = GridSearchCV(\n",
    "    estimator=model_v2, \n",
    "    param_grid=params_2,\n",
    "    scoring=scoring, \n",
    "    cv=5,\n",
    "    refit='Accuracy')\n",
    "gs_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'max_depth': 6, 'min_child_weight': 6}, best score: 0.9060890447751762\n"
     ]
    }
   ],
   "source": [
    "tuned_params['max_depth'] = gs_2.best_params_['max_depth']\n",
    "tuned_params['min_child_weight'] = gs_2.best_params_['min_child_weight']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_2.best_params_, gs_2.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 14.1944 seconds\n",
      "Accuracy score for training set: 0.9380.\n",
      "F1 score for training set: 0.6873.\n",
      "Accuracy score for test set: 0.9110.\n",
      "F1 score for test set: 0.5444.\n"
     ]
    }
   ],
   "source": [
    "model_v3 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'])\n",
    "train_predict(model_v3, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.7. Fourth tune: subsample and colsample_bytree\n",
    "Tuning subsample and colsample_bytree parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=6, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit='Accuracy',\n",
       "       return_train_score='warn',\n",
       "       scoring={'Accuracy': make_scorer(accuracy_score), 'F1-Score': make_scorer(f1_score)},\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_3 = {\n",
    "    'subsample':[0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree':[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "gs_3 = GridSearchCV(\n",
    "    estimator=model_v3, \n",
    "    param_grid=params_3,\n",
    "    scoring=scoring, \n",
    "    cv=5,\n",
    "    refit='Accuracy')\n",
    "gs_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters and values found were: {'colsample_bytree': 1.0, 'subsample': 0.8}, best score: 0.9064366290643663\n"
     ]
    }
   ],
   "source": [
    "tuned_params['colsample_bytree'] = gs_3.best_params_['colsample_bytree']\n",
    "tuned_params['subsample'] = gs_3.best_params_['subsample']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_3.best_params_, gs_3.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training classifier XGBClassifier using a training set size of 31647\n",
      "Trained model in 15.1605 seconds\n",
      "Accuracy score for training set: 0.9373.\n",
      "F1 score for training set: 0.6830.\n",
      "Accuracy score for test set: 0.9115.\n",
      "F1 score for test set: 0.5476.\n"
     ]
    }
   ],
   "source": [
    "model_v4 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'], \n",
    "    subsample=tuned_params['subsample'], \n",
    "    colsample_bytree=tuned_params['colsample_bytree'])\n",
    "train_predict(model_v4, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.8. Fifth tune: reg_alpha and reg_lambda\n",
    "Tuning reg_alpha and reg_lambda parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated (<ipython-input-25-687bd7c50edc>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-25-687bd7c50edc>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    cv=cv_sets,cv=5,\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m keyword argument repeated\n"
     ]
    }
   ],
   "source": [
    "params_4 = {\n",
    "    'reg_alpha':[x for x in range(0, 6)],\n",
    "    'reg_lambda':[x for x in range(1, 7)]\n",
    "}\n",
    "gs_4 = GridSearchCV(\n",
    "    estimator=model_v4, \n",
    "    param_grid=params_4, \n",
    "    scoring=scoring, \n",
    "    cv=5,\n",
    "    refit='Accuracy')\n",
    "gs_4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_params['reg_alpha'] = gs_4.best_params_['reg_alpha']\n",
    "tuned_params['reg_lambda'] = gs_4.best_params_['reg_lambda']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_4.best_params_, gs_4.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v5 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'], \n",
    "    subsample=tuned_params['subsample'], \n",
    "    colsample_bytree=tuned_params['colsample_bytree'],\n",
    "    reg_alpha=tuned_params['reg_alpha'],\n",
    "    reg_lambda=tuned_params['reg_lambda'])\n",
    "train_predict(model_v5, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.9. Sixth tune: gamma\n",
    "Tuning gamma parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_5 = {\n",
    "    'gamma':[x * 0.1 for x in range(0, 11)]\n",
    "}\n",
    "gs_5 = GridSearchCV(\n",
    "    estimator=model_v5, \n",
    "    param_grid=params_5,\n",
    "    scoring=scoring, \n",
    "    cv=5,\n",
    "    refit='Accuracy')\n",
    "gs_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_params['gamma'] = gs_5.best_params_['gamma']\n",
    "print(\"The best parameters and values found were: {}, best score: {}\".format(gs_5.best_params_, gs_5.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v6 = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=tuned_params['scale_pos_weight'],\n",
    "    objective=tuned_params['objective'], \n",
    "    max_depth=tuned_params['max_depth'],\n",
    "    min_child_weight=tuned_params['min_child_weight'], \n",
    "    subsample=tuned_params['subsample'], \n",
    "    colsample_bytree=tuned_params['colsample_bytree'],\n",
    "    reg_alpha=tuned_params['reg_alpha'],\n",
    "    reg_lambda=tuned_params['reg_lambda'],\n",
    "    gamma=tuned_params['gamma'])\n",
    "train_predict(model_v6, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.10. Tuned Parameters\n",
    "Printing the best values found for model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:<25} {:<10}\".format('Parameter','Value'))\n",
    "for k, v in tuned_params.items():\n",
    "    print(\"{:<25} {:<10}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### 6. Final Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Model Benchmark\n",
    "Creating a Dummy Classifier which Predicts the Majority Class and XGBoost untuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=1)\n",
    "train_predict(dummy_clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_untuned_model = XGBClassifier(random_state=1)\n",
    "train_predict(xgb_untuned_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgb_tuned_model = XGBClassifier(\n",
    "    random_state=1,\n",
    "    scale_pos_weight=1,\n",
    "    objective='reg:logistic', \n",
    "    max_depth=6, \n",
    "    min_child_weight=3, \n",
    "    subsample=1, \n",
    "    colsample_bytree=1,\n",
    "    reg_alpha=1,\n",
    "    reg_lambda=1,\n",
    "    gamma=0.7)\n",
    "train_predict(final_xgb_tuned_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Feature Importance\n",
    "Printing feature importance of the final tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = plot_importance(final_xgb_tuned_model, max_num_features=6)\n",
    "chart.figure.set_size_inches(14, 5)\n",
    "plt.title('Top 5 Importance Features',fontsize=15)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.ylabel('Feature',fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
